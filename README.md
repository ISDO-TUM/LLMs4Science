# Replication package for _LLMs for Science: Usage for Code Generation and Data Analysis_

This is the replication package for the pre-print _LLMs for Science: Usage for Code Generation and Data Analysis_, which studies the use of LLM-tools for code generation in the scientific process.

Following open science principles, and to support replicability, we publish this replication
package alongside recording all our interactions with the tools and our evaluation criteria.

## Structure

The logs of our interactions with the tools are structured by use case. They contain two logs for each of our two authors conducting the experiments.
- [Code_Generation](https://github.com/luuca78/LLMs4Science/tree/main/Code_Generation)
- [Data Analysis](https://github.com/luuca78/LLMs4Science/tree/main/Data_Analysis)
- [Data Visualization](https://github.com/luuca78/LLMs4Science/tree/main/Data_Visualization)

We provide our assessment rubric, used to assess the above mentioned results. For convenience, they're provided in different formats.
- [Rubric Assessment.csv](https://github.com/luuca78/LLMs4Science/blob/main/Rubric%20Assessment.csv)
- [Rubric Assessment.pdf](https://github.com/luuca78/LLMs4Science/blob/main/Rubric%20Assessment.pdf)
- [Rubric Assessment.xlsx](https://github.com/luuca78/LLMs4Science/blob/main/Rubric%20Assessment.pdf)

 We have compiled some examples of misleading results for the data analysis and visualization use cases.

- [examples_misleading_results.pdf](https://github.com/luuca78/LLMs4Science/blob/main/examples_misleading_results.pdf)
